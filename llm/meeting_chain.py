import os
import json
import re
import logging
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
from typing import Literal, TypedDict
import concurrent.futures
from wiki.wiki_retriever import WikiRetriever
from llm.json_fixer import JsonFixer
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì • ë° ë¡œê¹…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
torch.set_printoptions(profile="full")
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì •ì˜ (ì…ì¶œë ¥ ê´€ë¦¬ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TaskState(TypedDict):
    meeting_note: str
    project_id: int
    position: list[str]
    prompt: dict
    main_task: dict
    AI: list | None
    BE: list | None
    FE: list | None
    CL: list | None
    validation_result: str
    feedback: str | None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ í´ë˜ìŠ¤ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MeetingTaskParser:
    def __init__(self):
        logger.info("Initializing MeetingTaskParser...")
        load_dotenv()
        self._token = os.getenv("HUGGINGFACE_API_KEY")
        if not self._token:
            logger.warning("HUGGINGFACE_API_KEY not found in environment variables!")
        # model_name = "mistralai/Ministral-8B-Instruct-2410"
        model_name = "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B"
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = AutoModelForCausalLM.from_pretrained(model_name, token=self._token).to(self.device)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name, token=self._token)
        self.json_fixer = JsonFixer()
        self.wiki_retriever = WikiRetriever()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ëª¨ë¸ ì‹¤í–‰ ë° JSON íŒŒì‹±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def run_model_and_parse(self, chat: list) -> list[dict]:
        inputs = self.tokenizer.apply_chat_template(
            chat,
            return_tensors="pt",
            return_dict=True,
            add_generation_prompt=True
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        outputs = self.model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=False,
            eos_token_id=self.tokenizer.eos_token_id
        )
        prompt_len = inputs["input_ids"].shape[1]
        gen_ids = outputs[0][prompt_len:]
        raw = self.tokenizer.decode(gen_ids, skip_special_tokens=True).strip()
        try:
            cleaned = re.sub(r"```json|```", "", raw).strip()
            parsed = json.loads(cleaned)
        except json.JSONDecodeError:
            parsed = self.json_fixer.fix_json(raw)
        return parsed

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # íšŒì˜ë¡ì—ì„œ í•µì‹¬ ì—…ë¬´ íƒœìŠ¤í¬ ì¶”ì¶œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
        
    def extract_core_tasks(self, state: TaskState) -> dict:
        meeting_note = state["meeting_note"]

        system_prompt = {
            "role": "system",
            "content": """
    ë‹¹ì‹ ì€ íŒ€ íšŒì˜ë¡ì—ì„œ í¬ì§€ì…˜ë³„ í•  ì¼ì„ ì •í™•íˆ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ğŸ”¹ **í¬ì§€ì…˜ ì •ì˜:**
    â€¢ AI: ì¸ê³µì§€ëŠ¥, ë¨¸ì‹ ëŸ¬ë‹, ìì—°ì–´ì²˜ë¦¬, ë°ì´í„° ë¶„ì„, AI ì•Œê³ ë¦¬ì¦˜ ê´€ë ¨ ì—…ë¬´
    â€¢ BE: ë°±ì—”ë“œ, ì„œë²„, API, ë°ì´í„°ë² ì´ìŠ¤, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê´€ë ¨ ì—…ë¬´
    â€¢ FE: í”„ë¡ íŠ¸ì—”ë“œ, UI/UX, ì›¹/ì•± í™”ë©´, ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤, í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ê´€ë ¨ ì—…ë¬´
    â€¢ CL: í´ë¼ìš°ë“œ, ì¸í”„ë¼, ë°°í¬, ëª¨ë‹ˆí„°ë§, DevOps, ì„œë²„ ê´€ë¦¬ ê´€ë ¨ ì—…ë¬´

    ğŸ”¹ **í•µì‹¬ ê·œì¹™:**
    1. **ì›ë¬¸ ì¶©ì‹¤ì„±**: íšŒì˜ë¡ì— ë‚˜ì˜¨ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©°, ì˜ì—­í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    2. **ì™„ì „ì„±**: íšŒì˜ë¡ì— ì–¸ê¸‰ëœ ëª¨ë“  ì‘ì—…ì„ ëˆ„ë½ ì—†ì´ ë¶„ë¥˜í•©ë‹ˆë‹¤
    3. **ì •í™•ì„±**: ê° ì‘ì—…ì„ ê°€ì¥ ì ì ˆí•œ í¬ì§€ì…˜ì— ë¶„ë¥˜í•©ë‹ˆë‹¤
    4. **ì¼ê´€ì„±**: ëª¨ë“  í¬ì§€ì…˜ í‚¤(AI, BE, FE, CL)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•©ë‹ˆë‹¤

    ğŸ”¹ **ì—°ê²°ì–´ ì²˜ë¦¬ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):**
    ë‹¤ìŒ ì—°ê²°ì–´ë¡œ ì´ì–´ì§„ ì‘ì—…ë“¤ì€ **ë°˜ë“œì‹œ ê°œë³„ ì‘ì—…ìœ¼ë¡œ ë¶„ë¦¬**í•˜ì„¸ìš”:
    â€¢ "ë°", "í•˜ê³ ", "ê·¸ë¦¬ê³ ", "ê³¼", "ì™€", "ë˜í•œ", "ë”ë¶ˆì–´", "ì•„ìš¸ëŸ¬"
    â€¢ ",", ";"ë¡œ êµ¬ë¶„ëœ í•­ëª©ë“¤
    â€¢ "Aì™€ B êµ¬í˜„" â†’ ["A êµ¬í˜„", "B êµ¬í˜„"]
    â€¢ "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° API ê°œë°œ" â†’ ["ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„", "API ê°œë°œ"]
    â€¢ "UI ê°œì„ í•˜ê³  ì„±ëŠ¥ ìµœì í™”" â†’ ["UI ê°œì„ ", "ì„±ëŠ¥ ìµœì í™”"]
    â€¢ "ëª¨ë¸ í•™ìŠµ, í‰ê°€, ë°°í¬" â†’ ["ëª¨ë¸ í•™ìŠµ", "ëª¨ë¸ í‰ê°€", "ëª¨ë¸ ë°°í¬"]

    ğŸ”¹ **ì‘ì—…ëª… í˜•ì‹:**
    â€¢ ì§§ê³  ê°„ê²°í•œ **ëª…ì‚¬êµ¬** ë˜ëŠ” **ë™ì‚¬+ëª…ì‚¬** í˜•íƒœ
    â€¢ ì˜ˆì‹œ: "ì‚¬ìš©ì ì¸ì¦ êµ¬í˜„", "ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”", "ë©”ì¸ í˜ì´ì§€ ê°œë°œ"
    â€¢ ê¸ˆì§€: ì¡°ì‚¬(ì„/ë¥¼/ì´/ê°€), ì¢…ê²°ì–´ë¯¸(ë‹¤/ìš”/í•¨), ë§ˆì¹¨í‘œ(.)
    â€¢ ì—°ê²°ì–´ ì œê±°: "ë°", "í•˜ê³ ", "ê·¸ë¦¬ê³ " ë“±ì€ ì‘ì—…ëª…ì—ì„œ ì™„ì „íˆ ì œê±°

    ğŸ”¹ **ë¶„ë¦¬ ì˜ˆì‹œ:**
    â€¢ "ë¡œê·¸ì¸ API ë° íšŒì›ê°€ì… ê¸°ëŠ¥ ê°œë°œ" 
      â†’ ["ë¡œê·¸ì¸ API ê°œë°œ", "íšŒì›ê°€ì… ê¸°ëŠ¥ ê°œë°œ"]
    â€¢ "ë°ì´í„° ì „ì²˜ë¦¬í•˜ê³  ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€"
      â†’ ["ë°ì´í„° ì „ì²˜ë¦¬", "ëª¨ë¸ í›ˆë ¨", "ëª¨ë¸ í‰ê°€"]
    â€¢ "í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ ê°œë°œê³¼ ë°±ì—”ë“œ API ì—°ë™"
      â†’ FE: ["ì»´í¬ë„ŒíŠ¸ ê°œë°œ"], BE: ["API ì—°ë™"]

    ğŸ”¹ **í¬ì§€ì…˜ë³„ í• ë‹¹ ì˜ˆì‹œ:**
    â€¢ "AI ëª¨ë¸ í•™ìŠµ" â†’ AI í¬ì§€ì…˜
    â€¢ "ë¡œê·¸ì¸ API ê°œë°œ" â†’ BE í¬ì§€ì…˜
    â€¢ "ëŒ€ì‹œë³´ë“œ UI ê°œì„ " â†’ FE í¬ì§€ì…˜
    â€¢ "ì„œë²„ ë°°í¬ ìë™í™”" â†’ CL í¬ì§€ì…˜

    ğŸ”¹ **ë¹ˆ í¬ì§€ì…˜ ì²˜ë¦¬:**
    í•´ë‹¹ í¬ì§€ì…˜ì— í•  ì¼ì´ ì—†ìœ¼ë©´ ë°˜ë“œì‹œ ë¹ˆ ë°°ì—´([])ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

    ğŸ”¹ **ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**
    {
      "AI": ["ì‘ì—…1", "ì‘ì—…2", ...] ë˜ëŠ” [],
      "BE": ["ì‘ì—…1", "ì‘ì—…2", ...] ë˜ëŠ” [],
      "FE": ["ì‘ì—…1", "ì‘ì—…2", ...] ë˜ëŠ” [],
      "CL": ["ì‘ì—…1", "ì‘ì—…2", ...] ë˜ëŠ” []
    }

    **ì¤‘ìš”**: 
    1. 4ê°œ í¬ì§€ì…˜ í‚¤ë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³ , í•´ë‹¹ ì—†ëŠ” í¬ì§€ì…˜ì€ ë¹ˆ ë°°ì—´([])ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    2. ì—°ê²°ì–´ë¡œ ë¬¶ì¸ ì‘ì—…ë“¤ì„ ë°˜ë“œì‹œ ê°œë³„ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê°ê° ì ì ˆí•œ í¬ì§€ì…˜ì— í• ë‹¹í•˜ì„¸ìš”.
            """
        }
        
        user_prompt = {
            "role": "user",
            "content": f"""
    ë‹¤ìŒ íšŒì˜ë¡ì„ ë¶„ì„í•˜ì—¬ í¬ì§€ì…˜ë³„ í•  ì¼ì„ ì •í™•íˆ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

    **íšŒì˜ë¡:**
    {meeting_note}

    **ë¶„ì„ ì§€ì¹¨:**
    1. íšŒì˜ë¡ì—ì„œ ì–¸ê¸‰ëœ ëª¨ë“  ì‘ì—…ì„ ì‹ë³„í•˜ì„¸ìš”
    2. **ì—°ê²°ì–´(ë°, í•˜ê³ , ê·¸ë¦¬ê³ , ì™€, ê³¼ ë“±)ë¡œ ì´ì–´ì§„ ì‘ì—…ë“¤ì„ ê°œë³„ ì‘ì—…ìœ¼ë¡œ ë¶„ë¦¬**í•˜ì„¸ìš”
    3. ê° ì‘ì—…ì„ ê°€ì¥ ì ì ˆí•œ í¬ì§€ì…˜(AI/BE/FE/CL)ì— ë¶„ë¥˜í•˜ì„¸ìš”
    4. íšŒì˜ë¡ ì›ë¬¸ì˜ í‘œí˜„ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, ì—°ê²°ì–´ëŠ” ì œê±°í•˜ì„¸ìš”
    5. í•´ë‹¹ í¬ì§€ì…˜ì— ì‘ì—…ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´([])ë¡œ ì„¤ì •í•˜ì„¸ìš”
    6. ë°˜ë“œì‹œ ëª¨ë“  í¬ì§€ì…˜ í‚¤(AI, BE, FE, CL)ë¥¼ í¬í•¨í•˜ì„¸ìš”

    **ë¶„ë¦¬ ì˜ˆì‹œ:**
    - "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° API ê°œë°œ" â†’ ["ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„", "API ê°œë°œ"]
    - "UI ì»´í¬ë„ŒíŠ¸ ê°œë°œí•˜ê³  ìŠ¤íƒ€ì¼ë§" â†’ ["UI ì»´í¬ë„ŒíŠ¸ ê°œë°œ", "ìŠ¤íƒ€ì¼ë§"]
    - "ëª¨ë¸ í›ˆë ¨, ê²€ì¦, ë°°í¬" â†’ ["ëª¨ë¸ í›ˆë ¨", "ëª¨ë¸ ê²€ì¦", "ëª¨ë¸ ë°°í¬"]

    JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
            """
        }

        return {'prompt': {'main_task': [system_prompt, user_prompt]}}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í•µì‹¬ íƒœìŠ¤í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_response(self, state: TaskState) -> dict:
        chat = state['prompt']['main_task']
        parsed = self.run_model_and_parse(chat)
        return {'main_task': parsed}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í¬ì§€ì…˜ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def route_to_subtasks(self, state: TaskState) -> list[str]:
        mapping = {
            "ai": "generate_AI_subtasks",
            "be": "generate_BE_subtasks",
            "fe": "generate_FE_subtasks",
            "cl": "generate_Cloud_subtasks",
        }
        return [mapping[p.lower()] for p in state['position'] if p.lower() in mapping]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í¬ì§€ì…˜ë³„ ì„¸ë¶€ íƒœìŠ¤í¬ ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def generate_position_response(self, state: TaskState, key: str) -> dict:
        tasks = state['main_task'][key]
        if not tasks or tasks == []:
            return {key: []}
        
        outputs = []
        
        for task in tasks:
            wiki_context = self.wiki_retriever.retrieve_wiki_context(task, state['project_id'])
            # ê¸°ë³¸ ê²°ê³¼
            result = {
                "position": key,
                "task": task,
                "subtasks": [f"{task} ë¶„ì„", f"{task} êµ¬í˜„", f"{task} ê²€í† "]
            }
            
            try:
                chat = [
                    {
                        "role": "system",
                        "content": f"""ë‹¹ì‹ ì€ {key} í¬ì§€ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
    {{
    "position": "{key}",
    "task": "{task}",
    "subtasks": ["ì„¸ë¶€ì‘ì—…1", "ì„¸ë¶€ì‘ì—…2", "ì„¸ë¶€ì‘ì—…3"]
    }}"""
                    },
                    {
                        "role": "user",
                        "content": f"""
    {wiki_context}ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì—… '{task}'ë¥¼ 3ê°œì˜ ì„¸ë¶€ ë‹¨ê³„ë¡œ ë¶„í•´í•˜ì„¸ìš”. 
    ì ˆëŒ€ ì„¤ëª…(description)ì€ ë¶™ì´ì§€ ë§ˆì„¸ìš”. 
    """
                    }
                ]
                
                parsed = self.run_model_and_parse(chat)
                
                # dict, listì— ë”°ë¥¸ ë³€í™˜
                if isinstance(parsed, dict) and "subtasks" in parsed:
                    result["subtasks"] = parsed["subtasks"]
                elif isinstance(parsed, list) and len(parsed) > 0:
                    first = parsed[0]
                    if isinstance(first, dict) and "subtasks" in first:
                        result["subtasks"] = first["subtasks"]
                        
            except Exception as e:
                print(f"[{key}] Error: {e}")
            
            outputs.append(result)
        
        return {key: outputs}
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # LLM í‰ê°€ ê¸°ë°˜ í’ˆì§ˆ íŒë‹¨ â†’ retry ì—¬ë¶€ íŒë‹¨
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def judge_quality_with_json_mode(self, state: TaskState) -> dict:
        """JSON ëª¨ë“œë¥¼ ì‚¬ìš©í•œ ë” ê°„ë‹¨í•œ ì ‘ê·¼ë²•"""
        meeting_note = state["meeting_note"]
        main_task = state["main_task"]

        llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0,
            model_kwargs={
                "response_format": {"type": "json_object"}
            }
        )

        messages = [
            SystemMessage(content="""
   ë‹¹ì‹ ì€ íšŒì˜ë¡ ë¶„ì„ ê²°ê³¼ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤.

    í‰ê°€ í›„ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

    ```json
    {
      "result": "pass" ë˜ëŠ” "fail",
      "failure_reasons": ["ì‹¤íŒ¨ ì´ìœ 1", "ì‹¤íŒ¨ ì´ìœ 2"],
      "improvement_suggestions": ["ê°œì„  ë°©ë²•1", "ê°œì„  ë°©ë²•2"]
    }
    ```

    **í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸:**

    1. ì˜¬ë°”ë¥¸ í¬ì§€ì…˜ ë¶„ë¥˜ ì—¬ë¶€
    2. ì›ë¬¸ í‘œí˜„ ì™œê³¡ ì—¬ë¶€


    ëª¨ë“  í•­ëª© ë§Œì¡± ì‹œ "pass", í•˜ë‚˜ë¼ë„ ë¯¸ë‹¬ ì‹œ "fail"ë¡œ íŒì •í•˜ì„¸ìš”.

    failì¼ ë•Œ ê°œì„  ë°©ë²•ì„ ì–´ë–¤ ë¶€ë¶„ì„ ì–´ë–»ê²Œ ìˆ˜ì •í•˜ê³  ì–´ë–¤ ë¶€ë¶„ì„ ì–´ë””ë¡œ ì˜®ê²¨ì•¼í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """),
            HumanMessage(content=f"""
    **íšŒì˜ë¡:**
    {meeting_note}

    **ë¶„ë¥˜ ê²°ê³¼:**
    {json.dumps(main_task, ensure_ascii=False, indent=2)}

    ìœ„ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
            """)
        ]

        try:
            response = llm.invoke(messages)
            evaluation_data = json.loads(response.content)
            
            # í”¼ë“œë°± ë¬¸ìì—´ ìƒì„±
            if evaluation_data["result"] == "pass":
                feedback = ""
            else:
                feedback_parts = []
                if evaluation_data.get("failure_reasons"):
                    feedback_parts.append("ì‹¤íŒ¨ì‚¬ìœ :")
                    for reason in evaluation_data["failure_reasons"]:
                        feedback_parts.append(f"- {reason}")
                
                if evaluation_data.get("improvement_suggestions"):
                    feedback_parts.append("\nê°œì„ ë°©í–¥:")
                    for suggestion in evaluation_data["improvement_suggestions"]:
                        feedback_parts.append(f"- {suggestion}")
                
                feedback = "\n".join(feedback_parts)

            return {
                "validation_result": evaluation_data["result"],
                "feedback": feedback
            }
            
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                "validation_result": "fail",
                "feedback": "í‰ê°€ ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì „ë°˜ì ì¸ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }
        except Exception as e:
            logger.error(f"judge_quality_with_json_mode ì˜¤ë¥˜: {e}")
            return {
                "validation_result": "fail",
                "feedback": "í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì „ë°˜ì ì¸ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì„¸ë¶€ íƒœìŠ¤í¬ ë³‘ë ¬ ìƒì„± (AI, BE, FE, CL)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_all_position_responses(self, state: TaskState) -> dict:
        positions = state["position"]
        results = {}
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_to_key = {
                executor.submit(self.generate_position_response, state, pos): pos
                for pos in positions
            }
            for future in concurrent.futures.as_completed(future_to_key):
                key = future_to_key[future]
                try:
                    results[key] = future.result()[key]
                except Exception as exc:
                    logger.warning(f"{key} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {exc}")
                    results[key] = None
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # judge ê²°ê³¼ì— ë”°ë¼ ë¶„ê¸°: retry or í¬ì§€ì…˜ ë…¸ë“œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def route_after_validation(self, state: TaskState) -> list[str]:
        # if state['validation_result'] == 'fail':
        #     return ["retry_node"]
        # else:
            return self.route_to_subtasks(state)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # retry_node: JSON ê²°ê³¼ ì¬ì‘ì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def retry(self, state: TaskState) -> dict:
        meeting_note = state["meeting_note"]
        main_task = state["main_task"]
        feedback = state["feedback"]
        
        system_prompt = {
            "role": "system",
            "content": """
    ë‹¹ì‹ ì€ íŒ€ íšŒì˜ë¡ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ, í’ˆì§ˆ ê²€ì¦ì—ì„œ ì‹¤íŒ¨í•œ JSON ê²°ê³¼ë¥¼ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤.

    ğŸ”¹ **í¬ì§€ì…˜ë³„ ì—…ë¬´ ì •ì˜:**
    â€¢ AI: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸, ìì—°ì–´ì²˜ë¦¬, ë°ì´í„° ë¶„ì„, AI ì•Œê³ ë¦¬ì¦˜ ê´€ë ¨
    â€¢ BE: ì„œë²„, API, ë°ì´í„°ë² ì´ìŠ¤, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê´€ë ¨  
    â€¢ FE: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤, ì›¹/ì•± í™”ë©´, UX/UI, í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ê´€ë ¨
    â€¢ CL: ì¸í”„ë¼, ë°°í¬, ëª¨ë‹ˆí„°ë§, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤, DevOps ê´€ë ¨


    ğŸ”¹ **ì¶œë ¥ í˜•ì‹:**
    {
      "AI": ["ì‘ì—…1", "ì‘ì—…2", ...],
      "BE": ["ì‘ì—…1", "ì‘ì—…2", ...], 
      "FE": ["ì‘ì—…1", "ì‘ì—…2", ...],
      "CL": ["ì‘ì—…1", "ì‘ì—…2", ...]
    }

    **ì¤‘ìš”:** ì•„ë˜ í”¼ë“œë°±ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì—¬ ê°œì„ ëœ ê²°ê³¼ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    """
        }
        
        user_prompt = {
            "role": "user",
            "content": f"""
    **íšŒì˜ë¡:**
    {meeting_note}

    **ì´ì „ ê²°ê³¼ (ì‹¤íŒ¨):**
    {json.dumps(main_task, ensure_ascii=False, indent=2)}

    **ğŸš¨ í’ˆì§ˆ ê²€ì¦ í”¼ë“œë°±:**
    {feedback}

    **ì§€ì‹œì‚¬í•­:**
    ìœ„ í”¼ë“œë°±ì—ì„œ ì§€ì ëœ ë¬¸ì œì ë“¤ì„ ì •í™•íˆ íŒŒì•…í•˜ê³ , ê°œì„ ë°©í–¥ì— ë”°ë¼ ì™„ë²½í•œ JSONì„ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.

    íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ì„ ì£¼ì˜ê¹Šê²Œ í™•ì¸í•˜ì„¸ìš”:
    - ëˆ„ë½ëœ ì‘ì—…ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì¶”ê°€
    - ì˜ëª» ë¶„ë¥˜ëœ ì‘ì—…ì´ ìˆë‹¤ë©´ ì˜¬ë°”ë¥¸ í¬ì§€ì…˜ìœ¼ë¡œ ì´ë™
    - ëª¨í˜¸í•œ í‘œí˜„ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ìˆ˜ì •
    - íšŒì˜ë¡ ì›ë¬¸ì˜ í‘œí˜„ì„ ìµœëŒ€í•œ ìœ ì§€

    ê°œì„ ëœ JSONì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
    """
        }
        
        return {'prompt': {'main_task': [system_prompt, user_prompt]}}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í¬ì§€ì…˜ë³„ ì„¸ë¶€ íƒœìŠ¤í¬ ë¶„ê¸°ìš© wrapper
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_AI_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "AI")

    def generate_BE_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "BE")

    def generate_FE_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "FE")

    def generate_Cloud_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "CL")
