import os
import json
import re
import logging
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer
from llm.wiki_retriever import retrieve_wiki_context
from llm.json_fixer import JsonFixer
import torch
from typing import TypedDict


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TaskState(TypedDict):
    meeting_note: str
    project_id: int
    position: list[str]
    prompt: dict        
    main_task: dict | None      
    AI: dict | None 
    BE: dict | None 
    FE: dict | None 
    CL: dict | None    


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ í´ë˜ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MeetingTaskParser:
    def __init__(self):
        logger.info("Initializing MeetingTaskParser...")
        load_dotenv()
        self._token = os.getenv("HUGGINGFACE_API_KEY")
        if not self._token:
            logger.warning("HUGGINGFACE_API_KEY not found in environment variables!")

        model_name = "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B"
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = AutoModelForCausalLM.from_pretrained(model_name, token=self._token).to(self.device)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name, token=self._token)
        self.json_fixer = JsonFixer()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê³µí†µ ëª¨ë¸ ì‹¤í–‰ ë° íŒŒì‹± í•¨ìˆ˜
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def run_model_and_parse(self, chat: list) -> list[dict]:
        inputs = self.tokenizer.apply_chat_template(
            chat,
            return_tensors="pt",
            return_dict=True,
            add_generation_prompt=True
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        outputs = self.model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=False,
            eos_token_id=self.tokenizer.eos_token_id
        )
        prompt_len = inputs["input_ids"].shape[1]
        gen_ids = outputs[0][prompt_len:]
        raw = self.tokenizer.decode(gen_ids, skip_special_tokens=True).strip()
        try:
            cleaned = re.sub(r"```json|```", "", raw).strip()
            parsed = json.loads(cleaned)
        except json.JSONDecodeError:
            parsed = self.json_fixer.fix_json(raw)
        return parsed

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # íšŒì˜ë¡ì—ì„œ í•µì‹¬ íƒœìŠ¤í¬ ì¶”ì¶œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def extract_core_tasks(self, state: TaskState) -> dict:
        meeting_note = state["meeting_note"]



        system_prompt = {
            "role": "system",
            "content": """
ë„ˆëŠ” íŒ€ íšŒì˜ë¡ì—ì„œ í¬ì§€ì…˜ë³„ í•  ì¼ì„ ë½‘ì•„ì£¼ëŠ” ì „ë¬¸ê°€ì•¼.

- í¬ì§€ì…˜ ì •ì˜:
â€¢ AI: ì¸ê³µì§€ëŠ¥ ê°œë°œ íŒŒíŠ¸
â€¢ BE: ë°±ì—”ë“œ ê°œë°œ íŒŒíŠ¸
â€¢ FE: í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ íŒŒíŠ¸
â€¢ CL: í´ë¼ìš°ë“œ ê°œë°œ íŒŒíŠ¸

- íšŒì˜ë¡ì— ë‚˜ì˜¨ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ í‚¤ì›Œë“œë¡œ ì‚¬ìš©í•˜ê³ , ì˜ì—­ ê¸ˆì§€ì•¼.
- ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í…œí”Œë¦¿ í˜•ì‹ê³¼ í‚¤ë¥¼ **ëª¨ë‘** í¬í•¨í•´ì•¼ í•´.
- ê° í¬ì§€ì…˜ í‚¤ëŠ” ë¬´ì¡°ê±´ ì¶œë ¥ì— í¬í•¨ë˜ë©°, í•  ì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´([])ë¡œ ì±„ì›Œì•¼ í•´.
- ì¶œë ¥ í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ ì§§ê³  ê°„ê²°í•œ **ëª…ì‚¬êµ¬** ë˜ëŠ” **ë™ì‚¬+ëª…ì‚¬** í˜•íƒœì—¬ì•¼ í•´.
- ì¡°ì‚¬Â·ì¢…ê²°ì–´ë¯¸, ë§ˆì¹¨í‘œ(.)ëŠ” ì ˆëŒ€ ì“°ì§€ ë§ˆ.

í…œí”Œë¦¿:
{
  "AI": [],
  "BE": [],
  "FE": [],
  "CL": []
}
"""
        }
        user_prompt = {
            "role": "user",
            "content": f"""
íšŒì˜ë¡:
'{meeting_note}'



ëª©í‘œ: ê° í¬ì§€ì…˜ ë³„ë¡œ ì˜¤ëŠ˜ í•  ì¼ì„ ì‹ë³„í•´ì„œ JSON í…œí”Œë¦¿ì— ë§ê²Œ ì‘ì„±í•´ì¤˜.
"""
        }
        return {'prompt': {'main_task': [system_prompt, user_prompt]}}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_response(self, state: TaskState) -> dict:
        chat = state['prompt']['main_task']
        parsed = self.run_model_and_parse(chat)
        return {'main_task': parsed}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë‹¤ìŒ ë¶„ê¸° ë…¸ë“œ ê²°ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def route_to_subtasks(self, state: TaskState) -> list[str]:
        mapping = {
            "ai": "generate_AI_subtasks",
            "be": "generate_BE_subtasks",
            "fe": "generate_FE_subtasks",
            "cl": "generate_Cloud_subtasks",
        }
        return [mapping[p.lower()] for p in state['position'] if p.lower() in mapping]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í¬ì§€ì…˜ë³„ ì„¸ë¶€ íƒœìŠ¤í¬ ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_position_response(self, state: TaskState, key: str) -> dict:
        tasks = state['main_task'][key]
        chat = [{
            "role": "system",
            "content": f"""
ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ **{key} í¬ì§€ì…˜ ì‘ì—… ëª©ë¡**ì„ ì„¸ë¶€ ì‘ì—…ìœ¼ë¡œ ë¶„í•´í•˜ë¼.

ğŸ”¹ ì…ë ¥
- `tasks`ëŠ” ì—¬ëŸ¬ ê°œì˜ ì‘ì—…ì„ ë‹´ì€ ë°°ì—´ì´ë‹¤.

ğŸ”¹ ì¶œë ¥ ì˜ˆì‹œ

            [
            {{  "position": "{key}",
                "task": "<ì›ë³¸ ì‘ì—…>",
                "subtasks": ["ì„¸ë¶€ 1", "ì„¸ë¶€ 2"]
            }}
            ]


ğŸ”¹ ê·œì¹™
- "task"ëŠ” ì…ë ¥ê°’ ê·¸ëŒ€ë¡œ
- "subtasks"ëŠ” 2~4ê°œ, ë™ì‚¬+ëª…ì‚¬ í˜•íƒœë¡œ ì‘ì„±
- ë§ˆì¹¨í‘œ, ì„¤ëª…, ì½”ë“œë¸”ëŸ­ ì—†ì´ JSON ë°°ì—´ í•˜ë‚˜ë§Œ ì¶œë ¥
ì…ë ¥ ì‘ì—… ëª©ë¡:
{tasks}
"""
        }]
        parsed = self.run_model_and_parse(chat)
        return {key: parsed}

    def generate_AI_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "AI")

    def generate_BE_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "BE")

    def generate_FE_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "FE")

    def generate_Cloud_response(self, state: TaskState) -> dict:
        return self.generate_position_response(state, "CL")
